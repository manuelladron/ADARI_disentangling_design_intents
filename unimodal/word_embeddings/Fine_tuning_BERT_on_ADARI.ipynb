{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine tuning BERT on ADARI",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeQLOc5KK-oB",
        "outputId": "962bec9a-a796-4630-e8c4-f2c39affebae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fee14901933e9ab7fff503de45ac8dd9d1879eab5963e1a88e7aae9f14dbd0e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxW_6XvDMqYG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizer, BertForMaskedLM, AdamW\n",
        "import json\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqTyalsFNniM"
      },
      "source": [
        "#Simply read in the text data\n",
        "with open('/content/furniture_cleaned.json','r') as file:\n",
        "    furniture = file.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67t1sBJ7M84u"
      },
      "source": [
        "data = json.loads(furniture)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVn4TxpPGu-"
      },
      "source": [
        "corpus = []\n",
        "for d in data:\n",
        "  # We're currently training on the artist quotes to understand the most about their design intents\n",
        "   if 'quotes' in d:\n",
        "    corpus.append(d['quotes'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICeFBN9-Oj8h",
        "outputId": "f0640d8a-a3c1-4058-e62e-8b5d44cef990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Load model and tokenizer from huggingface\n",
        "bert = BertForMaskedLM.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8P6sp7CSlt_"
      },
      "source": [
        "#Simply flattening the list\n",
        "corpus = [text for quotes_list in corpus for text in quotes_list ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ec8iat3O2F-",
        "outputId": "5f1f3e10-6ecc-402b-c2f4-e479ea264ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "seq_len = [len(i.split()) for i in corpus]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f84e4afe3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eEGY7JWR-ki"
      },
      "source": [
        "max_seq_len = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxHAX8KESD-e",
        "outputId": "05452076-b67c-4971-b8b1-bc59ddd538c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# tokenize and encode sequences in the training set, also pads the tokens\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    corpus,\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTt95PB2V9gD"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZH9-Vu7WNq_"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 16\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE5zaHvThGTc"
      },
      "source": [
        "def get_proper_logits_labels(sent_id, logits, indexes):\n",
        "  labels = torch.zeros(len(sent_id), dtype=torch.long)\n",
        "  # 30522 is the length of the vocabulary\n",
        "  logits_new = torch.zeros(len(logits), 30522, dtype=torch.float64)\n",
        "  for i in range(len(labels)):\n",
        "    # try:\n",
        "    labels[i] = sent_id[i][indexes[i]]\n",
        "    logits_new[i] = logits[i][indexes[i]]\n",
        "    # except:\n",
        "      # print(labels)\n",
        "      # print(sent_id)\n",
        "      # print(indexes)\n",
        "      # print(i)\n",
        "      # labels[i] = sent_id[i][indexes[i]]\n",
        "      # logits_new[i] = logits[i][indexes[i]]\n",
        "  return labels, logits_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2mAg2Hk8AhY"
      },
      "source": [
        "bert = bert.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFNI9pCjfzLU"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "  #Create AdamW optimizer\n",
        "  optim = AdamW(bert.parameters(), lr=5e-5)\n",
        "\n",
        "  # loss function\n",
        "  cross_entropy = nn.CrossEntropyLoss()\n",
        "  \n",
        "  bert.train()\n",
        "\n",
        "  maskid = tokenizer.vocab['[MASK]']\n",
        "\n",
        "  for sent_id, att_mask in train_dataloader:\n",
        "    \n",
        "    #Create a masked copy of ids for the model to predict\n",
        "    sent_id = sent_id.to(device)\n",
        "    inp = sent_id.clone()\n",
        "    indexes = [1] * 16\n",
        "    att_mask = att_mask.to(device)\n",
        "\n",
        "    #Mask a word in each sentence for the model to predict\n",
        "    for sentence in inp:\n",
        "      i = np.random.randint(0, max_seq_len)\n",
        "      #Randomly choose a word to mask that isn't just a pad\n",
        "      while (sentence[i] == 0):\n",
        "        i = np.random.randint (0, max_seq_len)\n",
        "      sentence[i] = maskid\n",
        "      indexes.append(i)\n",
        "\n",
        "    l = bert(inp, attention_mask = att_mask, return_dict = True)\n",
        "    logits = l.logits\n",
        "    \n",
        "    # print(len(indexes))\n",
        "    # print(inp.shape)\n",
        "    # print(sent_id.shape)\n",
        "    # print(logits.shape)\n",
        "    labels, logits = get_proper_logits_labels(sent_id, logits, indexes)\n",
        "\n",
        "    loss = cross_entropy(logits, labels)\n",
        "    loss.backward(retain_graph=True)\n",
        "    optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g5NAqnmxrIN",
        "outputId": "efd2882e-2856-48a1-d3ae-6cbc5fa8519a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "for i in range(5):\n",
        "  #save weights of model\n",
        "  path = 'saved_weights.pt'\n",
        "  torch.save(bert.state_dict(), 'saved_weights' + str(i) + '.pt')\n",
        "  print(\"Started epoch \" + str(i))\n",
        "  train()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started epoch 0\n",
            "Started epoch 1\n",
            "Started epoch 2\n",
            "Started epoch 3\n",
            "Started epoch 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRj5UmaXn62I",
        "outputId": "5f93d938-053c-4838-c8fb-343057a6d4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "for i in range(5):\n",
        "  #save weights of model\n",
        "  files.download('saved_weights' + str(i) + '.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3d46d80b-07b2-47db-aff6-583b4f1fd1f1\", \"saved_weights0.pt\", 438145243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_317aafa9-16e8-4341-8200-40e2dc01c929\", \"saved_weights1.pt\", 438145243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4763d64a-116f-4101-9169-7faabdd07acc\", \"saved_weights2.pt\", 438145243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c9a70ff7-a13f-49ed-8b07-40b494847125\", \"saved_weights3.pt\", 438145243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f0493128-f6b4-48f0-8ce7-7e5c5d043c40\", \"saved_weights4.pt\", 438145243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dz3Cxb_gWFY",
        "outputId": "30a4b84e-da09-41a1-8413-da2689422add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "bert.load_state_dict(torch.load('saved_weights4.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta8NVJ7VR9cM"
      },
      "source": [
        "def get_embedding(s, words = None):\n",
        "  # tokenize and encode sequences in the test set\n",
        "    tokens = tokenizer.batch_encode_plus(\n",
        "        [s],\n",
        "        max_length = 50,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "\n",
        "    bert.eval()\n",
        "\n",
        "    seq = torch.tensor(tokens['input_ids'])\n",
        "    mask = torch.tensor(tokens['attention_mask'])\n",
        "\n",
        "    # dataLoader for train set\n",
        "    \n",
        "\n",
        "    torch.no_grad()\n",
        "    outputs = bert(seq, mask)\n",
        "    hidden_states = outputs[1]\n",
        "    embeddings = hidden_states[-2][0]\n",
        "    embeddings = torch.sum(token_vecs)  \n",
        "    return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2BUFYmlgJMr",
        "outputId": "b6fe3dd9-ffda-436b-ffa4-ed4d72fac467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "out = get_embedding('Bro what is up')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiKEoXto5EUP",
        "outputId": "9558ef96-10ed-44d8-c02e-d704306ce773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hidden_states"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.5306, -0.5524,  1.0517,  ..., -1.2708,  1.0737, -1.4077],\n",
              "          [-0.4816, -0.4939,  0.5471,  ..., -0.5976, -0.1390, -1.7710],\n",
              "          [-1.1673, -0.4776,  1.0655,  ..., -0.4274,  0.9424, -2.1420],\n",
              "          ...,\n",
              "          [-0.7248, -0.6990,  1.3732,  ...,  0.3083, -0.4028, -0.5759],\n",
              "          [-0.7088, -0.7440,  1.3811,  ..., -0.7950,  0.4830, -1.7952],\n",
              "          [ 0.4350,  0.1419,  1.2721,  ..., -0.7501, -0.3418, -0.5896]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 0.3137,  0.7381, -0.5180,  ...,  0.5350, -0.1954, -0.1805],\n",
              "          [ 0.3038,  0.7620, -0.5090,  ...,  0.5296, -0.2141, -0.1812],\n",
              "          [ 0.3113,  0.7377, -0.5206,  ...,  0.5371, -0.1930, -0.1650],\n",
              "          ...,\n",
              "          [ 0.2913,  0.7583, -0.5208,  ...,  0.5404, -0.2028, -0.1532],\n",
              "          [ 0.2921,  0.7609, -0.5179,  ...,  0.5374, -0.2083, -0.1581],\n",
              "          [ 0.2912,  0.7590, -0.5202,  ...,  0.5402, -0.2037, -0.1544]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 0.1992,  0.0024, -0.7828,  ..., -0.0760, -0.1878, -0.4578],\n",
              "          [ 0.1992,  0.0024, -0.7828,  ..., -0.0760, -0.1878, -0.4579],\n",
              "          [ 0.1992,  0.0024, -0.7828,  ..., -0.0760, -0.1878, -0.4578],\n",
              "          ...,\n",
              "          [ 0.1992,  0.0024, -0.7828,  ..., -0.0760, -0.1878, -0.4579],\n",
              "          [ 0.1992,  0.0024, -0.7828,  ..., -0.0760, -0.1878, -0.4579],\n",
              "          [ 0.1992,  0.0024, -0.7828,  ..., -0.0760, -0.1878, -0.4579]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[-1.5041,  0.1976,  1.4839,  ...,  0.7250,  0.8416, -1.1204],\n",
              "          [-1.5041,  0.1976,  1.4839,  ...,  0.7250,  0.8416, -1.1204],\n",
              "          [-1.5041,  0.1976,  1.4839,  ...,  0.7250,  0.8416, -1.1204],\n",
              "          ...,\n",
              "          [-1.5041,  0.1976,  1.4839,  ...,  0.7250,  0.8416, -1.1204],\n",
              "          [-1.5041,  0.1976,  1.4839,  ...,  0.7250,  0.8416, -1.1204],\n",
              "          [-1.5041,  0.1976,  1.4839,  ...,  0.7250,  0.8416, -1.1204]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[-1.6223, -0.3786,  1.9505,  ...,  0.8160, -0.2329,  0.4220],\n",
              "          [-1.6223, -0.3786,  1.9505,  ...,  0.8160, -0.2329,  0.4220],\n",
              "          [-1.6223, -0.3786,  1.9505,  ...,  0.8160, -0.2329,  0.4220],\n",
              "          ...,\n",
              "          [-1.6223, -0.3786,  1.9505,  ...,  0.8160, -0.2329,  0.4220],\n",
              "          [-1.6223, -0.3786,  1.9505,  ...,  0.8160, -0.2329,  0.4220],\n",
              "          [-1.6223, -0.3786,  1.9505,  ...,  0.8160, -0.2329,  0.4220]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 0.0105,  0.8554,  0.1736,  ..., -0.7159,  1.3245,  0.6804],\n",
              "          [ 0.0105,  0.8554,  0.1736,  ..., -0.7159,  1.3245,  0.6804],\n",
              "          [ 0.0105,  0.8554,  0.1736,  ..., -0.7159,  1.3245,  0.6804],\n",
              "          ...,\n",
              "          [ 0.0105,  0.8554,  0.1736,  ..., -0.7159,  1.3245,  0.6804],\n",
              "          [ 0.0105,  0.8554,  0.1736,  ..., -0.7159,  1.3245,  0.6804],\n",
              "          [ 0.0105,  0.8554,  0.1736,  ..., -0.7159,  1.3245,  0.6804]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 2.0259, -0.6141, -0.8567,  ..., -0.3936,  0.2459,  0.3466],\n",
              "          [ 2.0259, -0.6141, -0.8567,  ..., -0.3936,  0.2459,  0.3466],\n",
              "          [ 2.0259, -0.6141, -0.8567,  ..., -0.3936,  0.2459,  0.3466],\n",
              "          ...,\n",
              "          [ 2.0259, -0.6141, -0.8567,  ..., -0.3936,  0.2459,  0.3466],\n",
              "          [ 2.0259, -0.6141, -0.8567,  ..., -0.3936,  0.2459,  0.3466],\n",
              "          [ 2.0259, -0.6141, -0.8567,  ..., -0.3936,  0.2459,  0.3466]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 1.1504, -0.5677, -0.2888,  ...,  0.0206, -0.7753,  0.1755],\n",
              "          [ 1.1504, -0.5677, -0.2888,  ...,  0.0206, -0.7753,  0.1755],\n",
              "          [ 1.1504, -0.5677, -0.2888,  ...,  0.0206, -0.7753,  0.1755],\n",
              "          ...,\n",
              "          [ 1.1504, -0.5677, -0.2888,  ...,  0.0206, -0.7753,  0.1755],\n",
              "          [ 1.1504, -0.5677, -0.2888,  ...,  0.0206, -0.7753,  0.1755],\n",
              "          [ 1.1504, -0.5677, -0.2888,  ...,  0.0206, -0.7753,  0.1755]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 1.7999, -0.7092, -1.3546,  ...,  0.8579, -0.2171, -0.1872],\n",
              "          [ 1.7999, -0.7092, -1.3546,  ...,  0.8579, -0.2171, -0.1872],\n",
              "          [ 1.7999, -0.7092, -1.3546,  ...,  0.8579, -0.2171, -0.1872],\n",
              "          ...,\n",
              "          [ 1.7999, -0.7092, -1.3546,  ...,  0.8579, -0.2171, -0.1872],\n",
              "          [ 1.7999, -0.7092, -1.3546,  ...,  0.8579, -0.2171, -0.1872],\n",
              "          [ 1.7999, -0.7092, -1.3546,  ...,  0.8579, -0.2171, -0.1872]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 1.2984, -0.4366,  1.4508,  ...,  0.3816, -0.9573,  0.4492],\n",
              "          [ 1.2984, -0.4366,  1.4508,  ...,  0.3816, -0.9573,  0.4492],\n",
              "          [ 1.2984, -0.4366,  1.4508,  ...,  0.3816, -0.9573,  0.4492],\n",
              "          ...,\n",
              "          [ 1.2984, -0.4366,  1.4508,  ...,  0.3816, -0.9573,  0.4492],\n",
              "          [ 1.2984, -0.4366,  1.4508,  ...,  0.3816, -0.9573,  0.4492],\n",
              "          [ 1.2984, -0.4366,  1.4508,  ...,  0.3816, -0.9573,  0.4492]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[ 1.1317,  0.3020,  0.3281,  ...,  0.6188, -0.3935,  0.4561],\n",
              "          [ 1.1317,  0.3020,  0.3281,  ...,  0.6188, -0.3935,  0.4561],\n",
              "          [ 1.1317,  0.3020,  0.3281,  ...,  0.6188, -0.3935,  0.4561],\n",
              "          ...,\n",
              "          [ 1.1317,  0.3020,  0.3281,  ...,  0.6188, -0.3935,  0.4561],\n",
              "          [ 1.1317,  0.3020,  0.3281,  ...,  0.6188, -0.3935,  0.4561],\n",
              "          [ 1.1317,  0.3020,  0.3281,  ...,  0.6188, -0.3935,  0.4561]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[-0.8169, -0.0040, -1.6076,  ...,  0.6145,  0.2759, -1.4596],\n",
              "          [-0.8169, -0.0040, -1.6076,  ...,  0.6145,  0.2759, -1.4596],\n",
              "          [-0.8169, -0.0040, -1.6076,  ...,  0.6145,  0.2759, -1.4596],\n",
              "          ...,\n",
              "          [-0.8169, -0.0040, -1.6076,  ...,  0.6145,  0.2759, -1.4596],\n",
              "          [-0.8169, -0.0040, -1.6076,  ...,  0.6145,  0.2759, -1.4596],\n",
              "          [-0.8169, -0.0040, -1.6076,  ...,  0.6145,  0.2759, -1.4596]]],\n",
              "        grad_fn=<NativeLayerNormBackward>),\n",
              " tensor([[[-1.0737,  0.1603, -0.2152,  ...,  0.0430,  0.2820,  1.1192],\n",
              "          [-1.0737,  0.1603, -0.2152,  ...,  0.0430,  0.2820,  1.1192],\n",
              "          [-1.0737,  0.1603, -0.2152,  ...,  0.0430,  0.2820,  1.1192],\n",
              "          ...,\n",
              "          [-1.0737,  0.1603, -0.2152,  ...,  0.0430,  0.2820,  1.1192],\n",
              "          [-1.0737,  0.1603, -0.2152,  ...,  0.0430,  0.2820,  1.1192],\n",
              "          [-1.0737,  0.1603, -0.2152,  ...,  0.0430,  0.2820,  1.1192]]],\n",
              "        grad_fn=<NativeLayerNormBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj4hrsvi45F6",
        "outputId": "e10be5ec-b960-47ad-ebc7-f503ec95bb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 50\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC-okwLy6wP8"
      },
      "source": [
        "token_vecs = hidden_states[-2][0]\n",
        "token_vecs = torch.sum(token_vecs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}