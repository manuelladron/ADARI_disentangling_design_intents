{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as dataF\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re\n",
    "import io\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "import pdb\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for file dset_dataloader.json\n",
    "def open_json(path):\n",
    "    f = open(path) \n",
    "    data = json.load(f) \n",
    "    f.close()\n",
    "    return data \n",
    "\n",
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar to visualize progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES\n",
    "im_path_fur = '../images/v2/full'\n",
    "\n",
    "# ONEHOTS\n",
    "onehots_vocab_p = '../json_files/ADARI_furniture_onehots_vocab.json'\n",
    "onehots_w2i_p = '../json_files/ADARI_furniture_onehots_w2i.json'\n",
    "onehots_i2w_p = '../json_files/ADARI_furniture_onehots_i2w.json'\n",
    "onehots_p = '../json_files/ADARI_furniture_onehots.json'\n",
    "\n",
    "# FILES FOR DATALOADER\n",
    "# dset_words_p = \"/Users/manuelladron/iCloud_archive/Documents/_CMU/PHD-CD/PHD-CD_Research/ADARI/json_files/cleaned/ADARI_v2/furniture/ADARI_furniture_words.json\"\n",
    "# vocab_p = \"/Users/manuelladron/iCloud_archive/Documents/_CMU/PHD-CD/PHD-CD_Research/ADARI/json_files/cleaned/ADARI_v2/furniture/ADARI_furniture_vocab_adjs.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open json files with embeddings \n",
    "onehots = open_json(onehots_p)\n",
    "onehots_vocab = open_json(onehots_vocab_p)\n",
    "onehots_w2i = open_json(onehots_w2i_p)\n",
    "onehots_i2w = open_json(onehots_i2w_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_dict(d):\n",
    "    l = list(d.items())\n",
    "    random.shuffle(l)\n",
    "    d = dict(l)\n",
    "    return d\n",
    "\n",
    "def splitDict(d_img_words, percent, val_number):\n",
    "\n",
    "    val_n = val_number\n",
    "    train_test_size = len(d_img_words) - val_n\n",
    "    train_n = int(train_test_size*percent)\n",
    "    test_n = train_test_size - train_n\n",
    "    \n",
    "    d_img_words = shuffle_dict(d_img_words)\n",
    "    \n",
    "    im_words = iter(d_img_words.items())      \n",
    "    \n",
    "    # Image - words\n",
    "    dtrain_imw = dict(itertools.islice(im_words, train_n))  \n",
    "    dtest_imw = dict(itertools.islice(im_words, test_n))   \n",
    "    dval_imw = dict(itertools.islice(im_words, val_n))\n",
    "    \n",
    "    \n",
    "    print('trainset size: ', len(dtrain_imw), 'dataset size: ',len(dtest_imw), 'val set size: ', len(dval_imw))\n",
    "    return dtrain_imw, dtest_imw, dval_imw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  13225 dataset size:  3307 val set size:  1000\n"
     ]
    }
   ],
   "source": [
    "dtrain_w, dtest_w, dval_w = splitDict(onehots, .8, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, onehots, w2i, i2w, image_path):\n",
    "        self.onehots_d = onehots\n",
    "        self.w2i = w2i\n",
    "        self.i2w = i2w\n",
    "        self.images_names = list(self.onehots_d.keys()) # names\n",
    "        self.onehots = list(self.onehots_d.values()) # onehots\n",
    "        self.image_path = image_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.onehots)\n",
    "    \n",
    "    def get_image_tensor(self, image_name):\n",
    "        \"\"\"\n",
    "        Gets image name and returns a tensor\n",
    "        \"\"\"\n",
    "        name = self.image_path + \"/\" + image_name\n",
    "        img = Image.open(name)\n",
    "        img = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor()])(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name_image = self.images_names[index]\n",
    "        img = self.get_image_tensor(name_image)\n",
    "        onehot = torch.FloatTensor(self.onehots[index])\n",
    "        \n",
    "        return img, onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MyDataset(dtrain_w, onehots_w2i, onehots_i2w, im_path_fur)\n",
    "dataset_test = MyDataset(dtest_w, onehots_w2i, onehots_i2w,im_path_fur)\n",
    "dataset_val = MyDataset(dval_w, onehots_w2i, onehots_i2w,  im_path_fur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 8 if cuda else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=False)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=len(dataset_val), shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],\n",
      "          [0.8902, 0.8941, 0.8980,  ..., 0.8784, 0.8745, 0.8706],\n",
      "          [0.8902, 0.8980, 0.9020,  ..., 0.8824, 0.8784, 0.8745],\n",
      "          ...,\n",
      "          [0.6314, 0.6471, 0.6667,  ..., 0.6196, 0.6314, 0.6431],\n",
      "          [0.6157, 0.6431, 0.6588,  ..., 0.6078, 0.6275, 0.6275],\n",
      "          [0.5922, 0.6196, 0.6431,  ..., 0.6196, 0.6039, 0.6000]],\n",
      "\n",
      "         [[0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],\n",
      "          [0.8902, 0.8941, 0.8980,  ..., 0.8784, 0.8745, 0.8706],\n",
      "          [0.8902, 0.8980, 0.9020,  ..., 0.8824, 0.8784, 0.8745],\n",
      "          ...,\n",
      "          [0.6118, 0.6314, 0.6510,  ..., 0.5961, 0.6078, 0.6196],\n",
      "          [0.5961, 0.6235, 0.6392,  ..., 0.5882, 0.5961, 0.5922],\n",
      "          [0.5725, 0.5961, 0.6157,  ..., 0.5961, 0.5765, 0.5725]],\n",
      "\n",
      "         [[0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],\n",
      "          [0.8902, 0.8941, 0.8980,  ..., 0.8784, 0.8745, 0.8706],\n",
      "          [0.8902, 0.8980, 0.9020,  ..., 0.8824, 0.8784, 0.8745],\n",
      "          ...,\n",
      "          [0.5804, 0.5961, 0.6118,  ..., 0.5608, 0.5686, 0.5804],\n",
      "          [0.5725, 0.5922, 0.6000,  ..., 0.5569, 0.5647, 0.5569],\n",
      "          [0.5490, 0.5686, 0.5804,  ..., 0.5686, 0.5529, 0.5490]]],\n",
      "\n",
      "\n",
      "        [[[0.4235, 0.3922, 0.3451,  ..., 0.7647, 0.7529, 0.7412],\n",
      "          [0.3608, 0.3804, 0.3569,  ..., 0.7686, 0.7608, 0.7569],\n",
      "          [0.2471, 0.2588, 0.2863,  ..., 0.7765, 0.7686, 0.7569],\n",
      "          ...,\n",
      "          [0.3176, 0.3569, 0.4157,  ..., 0.3333, 0.3255, 0.3333],\n",
      "          [0.4824, 0.5333, 0.5529,  ..., 0.3020, 0.3059, 0.3216],\n",
      "          [0.5412, 0.5725, 0.5216,  ..., 0.2745, 0.2824, 0.2980]],\n",
      "\n",
      "         [[0.2824, 0.2745, 0.2431,  ..., 0.6706, 0.6588, 0.6471],\n",
      "          [0.2000, 0.2078, 0.2039,  ..., 0.6745, 0.6667, 0.6627],\n",
      "          [0.1373, 0.1333, 0.1412,  ..., 0.6902, 0.6706, 0.6627],\n",
      "          ...,\n",
      "          [0.2078, 0.2471, 0.2941,  ..., 0.2039, 0.2039, 0.2157],\n",
      "          [0.3373, 0.3843, 0.4000,  ..., 0.1765, 0.1843, 0.2039],\n",
      "          [0.3804, 0.4000, 0.3647,  ..., 0.1686, 0.1765, 0.1882]],\n",
      "\n",
      "         [[0.1765, 0.1843, 0.1725,  ..., 0.5608, 0.5490, 0.5373],\n",
      "          [0.0941, 0.0980, 0.1020,  ..., 0.5647, 0.5569, 0.5529],\n",
      "          [0.0588, 0.0510, 0.0471,  ..., 0.5843, 0.5686, 0.5569],\n",
      "          ...,\n",
      "          [0.1137, 0.1569, 0.1961,  ..., 0.1176, 0.1176, 0.1373],\n",
      "          [0.1922, 0.2314, 0.2549,  ..., 0.1020, 0.1098, 0.1333],\n",
      "          [0.2353, 0.2235, 0.2235,  ..., 0.1098, 0.1098, 0.1216]]],\n",
      "\n",
      "\n",
      "        [[[0.8588, 0.8588, 0.8627,  ..., 0.9176, 0.9216, 0.9216],\n",
      "          [0.8588, 0.8588, 0.8627,  ..., 0.9176, 0.9216, 0.9216],\n",
      "          [0.8588, 0.8588, 0.8627,  ..., 0.9176, 0.9216, 0.9216],\n",
      "          ...,\n",
      "          [0.8824, 0.8824, 0.8863,  ..., 0.9176, 0.9176, 0.9176],\n",
      "          [0.8706, 0.8706, 0.8745,  ..., 0.9098, 0.9098, 0.9098],\n",
      "          [0.8510, 0.8588, 0.8549,  ..., 0.8941, 0.8980, 0.8980]],\n",
      "\n",
      "         [[0.8745, 0.8745, 0.8784,  ..., 0.9333, 0.9373, 0.9373],\n",
      "          [0.8745, 0.8745, 0.8784,  ..., 0.9333, 0.9373, 0.9373],\n",
      "          [0.8745, 0.8745, 0.8784,  ..., 0.9333, 0.9373, 0.9373],\n",
      "          ...,\n",
      "          [0.8980, 0.8980, 0.8980,  ..., 0.9333, 0.9333, 0.9333],\n",
      "          [0.8863, 0.8863, 0.8902,  ..., 0.9255, 0.9255, 0.9255],\n",
      "          [0.8706, 0.8745, 0.8745,  ..., 0.9098, 0.9137, 0.9137]],\n",
      "\n",
      "         [[0.8863, 0.8863, 0.8902,  ..., 0.9373, 0.9412, 0.9412],\n",
      "          [0.8863, 0.8863, 0.8902,  ..., 0.9373, 0.9412, 0.9412],\n",
      "          [0.8863, 0.8863, 0.8902,  ..., 0.9373, 0.9412, 0.9412],\n",
      "          ...,\n",
      "          [0.9098, 0.9098, 0.9137,  ..., 0.9451, 0.9451, 0.9451],\n",
      "          [0.8980, 0.8980, 0.9020,  ..., 0.9373, 0.9373, 0.9373],\n",
      "          [0.8824, 0.8902, 0.8863,  ..., 0.9216, 0.9255, 0.9255]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.9569, 0.9569, 0.9608,  ..., 0.9843, 0.9843, 0.9843],\n",
      "          [0.9647, 0.9686, 0.9686,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.9647, 0.9686, 0.9686,  ..., 0.9882, 0.9882, 0.9882]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.9569, 0.9569, 0.9608,  ..., 0.9843, 0.9843, 0.9843],\n",
      "          [0.9647, 0.9686, 0.9686,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.9647, 0.9686, 0.9686,  ..., 0.9882, 0.9882, 0.9882]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.9569, 0.9569, 0.9608,  ..., 0.9843, 0.9843, 0.9843],\n",
      "          [0.9647, 0.9686, 0.9686,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.9647, 0.9686, 0.9686,  ..., 0.9882, 0.9882, 0.9882]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0078, 0.0039,  ..., 0.0157, 0.0157, 0.0118],\n",
      "          [0.0078, 0.0078, 0.0078,  ..., 0.0196, 0.0118, 0.0196],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.0863, 0.0431, 0.0510],\n",
      "          ...,\n",
      "          [0.0078, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0078, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0157, 0.0118, 0.0118]],\n",
      "\n",
      "         [[0.0157, 0.0157, 0.0196,  ..., 0.0157, 0.0118, 0.0078],\n",
      "          [0.0157, 0.0196, 0.0196,  ..., 0.0196, 0.0157, 0.0157],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0667, 0.0314, 0.0353],\n",
      "          ...,\n",
      "          [0.0078, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0078, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0157, 0.0118, 0.0118]],\n",
      "\n",
      "         [[0.0588, 0.0627, 0.0627,  ..., 0.0078, 0.0000, 0.0000],\n",
      "          [0.0510, 0.0549, 0.0510,  ..., 0.0078, 0.0078, 0.0039],\n",
      "          [0.0353, 0.0353, 0.0275,  ..., 0.0235, 0.0157, 0.0196],\n",
      "          ...,\n",
      "          [0.0157, 0.0196, 0.0196,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0157, 0.0196, 0.0196,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0196, 0.0196, 0.0196,  ..., 0.0157, 0.0118, 0.0118]]],\n",
      "\n",
      "\n",
      "        [[[0.8392, 0.8510, 0.8588,  ..., 0.7294, 0.7294, 0.7333],\n",
      "          [0.8510, 0.8549, 0.8627,  ..., 0.7412, 0.7412, 0.7373],\n",
      "          [0.8510, 0.8510, 0.8627,  ..., 0.7569, 0.7490, 0.7412],\n",
      "          ...,\n",
      "          [0.2118, 0.1686, 0.2039,  ..., 0.1529, 0.2235, 0.3333],\n",
      "          [0.2039, 0.1686, 0.2000,  ..., 0.2353, 0.2353, 0.3490],\n",
      "          [0.2039, 0.1608, 0.1922,  ..., 0.3608, 0.3569, 0.3647]],\n",
      "\n",
      "         [[0.7882, 0.8000, 0.8078,  ..., 0.6824, 0.6863, 0.6941],\n",
      "          [0.8000, 0.8039, 0.8118,  ..., 0.6941, 0.6980, 0.6980],\n",
      "          [0.8000, 0.8000, 0.8118,  ..., 0.7098, 0.7059, 0.7020],\n",
      "          ...,\n",
      "          [0.1647, 0.1294, 0.1608,  ..., 0.1098, 0.1804, 0.2667],\n",
      "          [0.1608, 0.1294, 0.1569,  ..., 0.1922, 0.1882, 0.2980],\n",
      "          [0.1608, 0.1255, 0.1490,  ..., 0.3137, 0.3098, 0.3137]],\n",
      "\n",
      "         [[0.7255, 0.7373, 0.7451,  ..., 0.6196, 0.6157, 0.6196],\n",
      "          [0.7333, 0.7412, 0.7490,  ..., 0.6314, 0.6275, 0.6196],\n",
      "          [0.7373, 0.7373, 0.7490,  ..., 0.6471, 0.6353, 0.6275],\n",
      "          ...,\n",
      "          [0.1294, 0.1020, 0.1294,  ..., 0.0941, 0.1373, 0.2039],\n",
      "          [0.1294, 0.0980, 0.1255,  ..., 0.1608, 0.1569, 0.2510],\n",
      "          [0.1333, 0.0941, 0.1137,  ..., 0.2627, 0.2627, 0.2706]]]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "# to test dataloader\n",
    "it = iter(test_dataloader)\n",
    "print(next(it))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = False # so we update the whole model \n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes, feature_extract, use_pretrained=False):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = 64\n",
    "    \n",
    "    return model_ft, input_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2486, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(onehots_w2i)\n",
    "model, input_size = initialize_model(num_classes, feature_extract)\n",
    "model.fc.weight.shape\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, accuracy_score\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "sgdr_partial = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.005)\n",
    "plateau = lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    result = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (image, target) in enumerate(loader):   \n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target) # Averaging losses from all vector components. \n",
    "\n",
    "        # We use sigmoid for prediction. Sigmoid is applied to each individual class in the 2700 classes. \n",
    "        # Therefore, if it's more than 0.5, we predict it as True. \n",
    "        preds = torch.sigmoid(output).data > 0.5\n",
    "        preds = preds.to(torch.float32)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        running_loss += loss.item() * image.shape[0]\n",
    "        \n",
    "        # Metrics \n",
    "        f1 = f1_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy(), average=\"samples\")*image.size(0)\n",
    "        precision = precision_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy(), average=\"samples\")*image.size(0)\n",
    "        accuracy = accuracy_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy())*image.size(0)\n",
    "\n",
    "        running_corrects += f1\n",
    "        running_precision += precision\n",
    "        running_accuracy += accuracy\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_f1 = running_corrects / len(loader.dataset)\n",
    "    epoch_precision = running_precision / len(loader.dataset)\n",
    "    epoch_acc = running_accuracy / len(loader.dataset)\n",
    "    \n",
    "    result.append('Training Loss: {:.4f} F1: {:.4f} Acc: {:.4f} Prec: {:.4f}'.format(epoch_loss, epoch_f1, epoch_acc, epoch_precision))\n",
    "    print(result)\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, target) in enumerate(loader):   \n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = torch.sigmoid(output).data > 0.5\n",
    "            preds = preds.to(torch.float32)\n",
    "\n",
    "            running_loss += loss.item() * image.shape[0]\n",
    "            \n",
    "            # Metrics \n",
    "            f1 = f1_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy(), average=\"samples\")*image.size(0)\n",
    "            precision = precision_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy(), average=\"samples\")*image.size(0)\n",
    "            accuracy = accuracy_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy())*image.size(0)\n",
    "\n",
    "            running_corrects += f1\n",
    "            running_precision += precision\n",
    "            running_accuracy += accuracy\n",
    "        \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_f1 = running_corrects / len(loader.dataset)\n",
    "    epoch_precision = running_precision / len(loader.dataset)\n",
    "    epoch_acc = running_accuracy / len(loader.dataset)\n",
    "    \n",
    "    result.append('Testing Loss: {:.4f} F1: {:.4f} Acc: {:.4f} Prec: {:.4f}'.format(epoch_loss, epoch_f1, epoch_acc, epoch_precision))\n",
    "    print(result)\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13225, 3307)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset), len(test_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCheckpoint(filename, batch_size):\n",
    "    checkpoint = {\n",
    "              'epoch': 5,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              \"batch_size\":batch_size,\n",
    "    } # save all important stuff\n",
    "    torch.save(checkpoint , filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training epoch 0/49 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Training Loss: 0.0203 F1: 0.0200 Acc: 0.0000 Prec: 0.0986']\n",
      "train epoch: 0, loss: 0.02031747657995819\n",
      "\n",
      "------Testing epoch 0/49 --------\n",
      "['Testing Loss: 0.0147 F1: 0.0777 Acc: 0.0000 Prec: 0.4179']\n",
      "test epoch: 0, loss: 0.014714983216449415\n",
      "-----Training epoch 1/49 --------\n",
      "['Training Loss: 0.0147 F1: 0.0187 Acc: 0.0000 Prec: 0.1002']\n",
      "train epoch: 1, loss: 0.014700609476205193\n",
      "\n",
      "------Testing epoch 1/49 --------\n",
      "['Testing Loss: 0.0147 F1: 0.0014 Acc: 0.0000 Prec: 0.0067']\n",
      "test epoch: 1, loss: 0.014739728231678061\n",
      "-----Training epoch 2/49 --------\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "save_model_path = './saved_models/multilabel_adam0.003_plateau/'\n",
    "epochs=50\n",
    "best_loss = 1000.0\n",
    "for i in range(epochs):\n",
    "    print('-----Training epoch {}/{} --------'.format(i,epochs-1))\n",
    "    tr_loss, tr_acc = train_epoch(model, train_dataloader, optimizer, criterion, sgdr_partial)\n",
    "    print('train epoch: {}, loss: {}'.format(i, tr_loss))\n",
    "    print()\n",
    "    print('------Testing epoch {}/{} --------'.format(i,epochs-1))\n",
    "    tst_loss, tst_acc = test_epoch(model, test_dataloader, criterion)\n",
    "    print('test epoch: {}, loss: {}'.format(i, tst_loss))\n",
    "    plateau.step(tst_loss)\n",
    "    \n",
    "    train_losses.append(tr_loss)\n",
    "    train_accs.append(tr_acc)\n",
    "    test_losses.append(tst_loss)\n",
    "    test_accs.append(tst_acc)\n",
    "    \n",
    "    if tst_loss < best_loss:\n",
    "        best_loss = tst_loss\n",
    "        save_path_resnet = save_model_path + 'resnet_{}.pt'.format(i)\n",
    "        createCheckpoint(save_path_resnet, 64)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_set):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for batch_idx, (image, target) in enumerate(loader):   \n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        preds = torch.sigmoid(output).data > 0.5\n",
    "        preds = preds.to(torch.float32)\n",
    "\n",
    "        running_loss += loss.item() * image.shape[0]\n",
    "\n",
    "        # Metrics \n",
    "        f1 = f1_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy(), average=\"samples\")*image.size(0)\n",
    "        precision = precision_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy(), average=\"samples\")*image.size(0)\n",
    "        accuracy = accuracy_score(target.to(\"cpu\").to(torch.int).numpy(), preds.to(\"cpu\").to(torch.int).numpy())*image.size(0)\n",
    "\n",
    "        running_corrects += f1\n",
    "        running_precision += precision\n",
    "        running_accuracy += accuracy\n",
    "        \n",
    "        \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_f1 = running_corrects / len(loader.dataset)\n",
    "    epoch_precision = running_precision / len(loader.dataset)\n",
    "    epoch_acc = running_accuracy / len(loader.dataset)\n",
    "    \n",
    "    result.append('Testing Loss: {:.4f} F1: {:.4f} Acc: {:.4f} Prec: {:.4f}'.format(epoch_loss, epoch_f1, epoch_acc, epoch_precision))\n",
    "    print(result)\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
