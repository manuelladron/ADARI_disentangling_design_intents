{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# directory containing all raw images\n",
    "IMG_PATH = \"/home/alex/CMU/777/ADARI/v2/full\"\n",
    "SENTS_PATH = \"/home/alex/CMU/777/ADARI/ADARI_furniture_sents.json\"\n",
    "\n",
    "def open_json(path):\n",
    "    f = open(path) \n",
    "    data = json.load(f) \n",
    "    f.close()\n",
    "    return data \n",
    "\n",
    "def save_json(file_path, data):\n",
    "    out_file = open(file_path, \"w\")\n",
    "    json.dump(data, out_file)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Load the pretrained ResNet50 and replace top fc layer.\"\"\"\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        resnet = torchvision.models.resnet50(pretrained=True)\n",
    "        resnet.eval()\n",
    "        modules = list(resnet.children())[:-1]      # delete the last fc (classification) layer.\n",
    "        self.resnet = torch.nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"Extract feature vectors from input images.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            features = self.resnet(images)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_to_images, im_names, patch_size = 8, img_size = 64):\n",
    "        self.img_path = path_to_images\n",
    "        self.images = im_names\n",
    "        self.patch_size = patch_size\n",
    "        self.img_size = img_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.images[index]\n",
    "        \n",
    "        name = self.img_path + \"/\" + image_name\n",
    "        img = Image.open(name)\n",
    "        \n",
    "        img = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(self.img_size),\n",
    "        torchvision.transforms.CenterCrop(self.img_size),\n",
    "        torchvision.transforms.ToTensor()])(img)\n",
    "        \n",
    "        # pad just in case\n",
    "        img = F.pad(img, (img.shape[2] % self.patch_size // 2, img.shape[2] % self.patch_size // 2,\n",
    "                         img.shape[1] % self.patch_size // 2, img.shape[1] % self.patch_size // 2))\n",
    "        \n",
    "        patches = {}\n",
    "        for i in range(img.shape[1] // self.patch_size):\n",
    "            for j in range(img.shape[2] // self.patch_size):\n",
    "                patches[(i,j)] =\\\n",
    "                    img[:, i*self.patch_size:(i+1)*self.patch_size, j*self.patch_size:(j+1)*self.patch_size]\n",
    "                \n",
    "        return patches, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im2sents = open_json(SENTS_PATH)\n",
    "dataset = ImageDataset(IMG_PATH, list(im2sents.keys()))\n",
    "encoder = EncoderCNN()\n",
    "encoder.to(device)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings = dict() # dictionary to store image embeddings\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (images, name) in enumerate(dataloader):\n",
    "        # Encode patches with CNN\n",
    "        patches = {}\n",
    "        for patch, im in images.items():\n",
    "            im = im.to(device)\n",
    "            out = encoder(im)\n",
    "            patches[patch] = out[0].cpu()\n",
    "        \n",
    "        image_embeddings[name] = patches\n",
    "        \n",
    "with open(\"fashionbert_resnet_patches8x8.json\", \"w\") as f:\n",
    "    json.dump(image_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}