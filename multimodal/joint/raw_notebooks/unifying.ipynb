{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re\n",
    "import io\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "import pdb\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for file dset_dataloader.json\n",
    "def open_json(path):\n",
    "    f = open(path) \n",
    "    data = json.load(f) \n",
    "    f.close()\n",
    "    return data \n",
    "\n",
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar to visualize progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES\n",
    "im_path_fur = '/home/ubuntu/ADARI/images/v2/full'\n",
    "# im_path_fur = \"../images/furniture/v2/full\" # small are 64x64, medium 256x256 and large 512x512\n",
    "\n",
    "# JSON_FILES\n",
    "# data_path_fur = \"../ADARI/json_files/cleaned/ADARI_v2/furniture_v2_c.json\"\n",
    "\n",
    "# WORD EMBEDDINGS\n",
    "word_embeddings_path = \"../json_files/fur_5c_50d_sk_glove_ft.json\"\n",
    "\n",
    "# IMAGE EMBEDDINGS\n",
    "img_embds_id_p = \"../json_files/afur_resnet_emb_id.json\"\n",
    "img_embds_name_p = \"../json_files/afur_resnet_emb_names.json\"\n",
    "\n",
    "# FILES FOR DATALOADER\n",
    "dset_words_p = \"../json_files/ADARI_v2_furniture_images_words.json\"\n",
    "# dset_sentences_p = \"../ADARI/json_files/ADARI_images_sentences_words/furniture/ADARI_v2_furniture_images_sentences.json\"\n",
    "# dset_sentences_POS_p = \"../ADARI/json_files/ADARI_images_sentences_words/furniture/ADARI_v2_furniture_images_sentences_tokenized.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open json files with embeddings \n",
    "image_embeddings = open_json(img_embds_name_p)\n",
    "dataset_labels = open_json(dset_words_p)\n",
    "labels_embeddings = open_json(word_embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dictionary of ordered labels to list of labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = '../json_files/glove.6B.50d.txt'\n",
    "with io.open(glove_path, 'r', encoding='utf8') as f:    \n",
    "    glove_file = f.read()\n",
    "    \n",
    "glove_sentences = glove_file.splitlines()\n",
    "glove_vocab = {}\n",
    "for sentence in glove_sentences:\n",
    "    word = sentence.split()[0]\n",
    "    embedding = np.array(sentence.split()[1:], dtype = float)\n",
    "    glove_vocab[word] = embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nasty temporal vector for unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glove_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        pass\n",
    "n_vec = i + 1\n",
    "hidden_dim = len(line.split(' ')) - 1\n",
    "\n",
    "vecs = np.zeros((n_vec, hidden_dim), dtype=np.float32)\n",
    "\n",
    "with open(glove_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        vecs[i] = np.array([float(n) for n in line.split(' ')[1:]], dtype=np.float32)\n",
    "\n",
    "AVG_VECTOR = np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_date(word):\n",
    "    rx = r\"[0-9]+(?:st|[nr]d|th)\"\n",
    "    if re.findall(rx, word, flags=re.I) != []:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def labels_dict2list(dset_words):\n",
    "    # The 2 dictionaries below for dataset dataloader\n",
    "    im2idx = dict()\n",
    "    im_words = dict()\n",
    "\n",
    "    # Temp lists \n",
    "    image_names = list(dset_words.keys())\n",
    "    words = list(dset_words.values())\n",
    "\n",
    "    # Iterate over length of dictionary and get im2idx and im_words \n",
    "    for i in range(len(image_names)):\n",
    "        im = image_names[i]\n",
    "        words_list = flatten(list(words[i].values()))\n",
    "        cleaned_w = []\n",
    "        for w in words_list:\n",
    "            if w != '\"the' and w != '\"The' and len(w) > 1 and is_date(w) != True:\n",
    "                cleaned_w.append(w)\n",
    "\n",
    "#         im_words[im] = cleaned_w\n",
    "        im_words[im] = list(set(cleaned_w))\n",
    "        im2idx[im] = i\n",
    "    return im_words, im2idx\n",
    "\n",
    "def create_vocab(dataset_labels):\n",
    "    \"\"\"\n",
    "    We have 17532 images and a total of 707852 adjectives, so average of 40 words per image\n",
    "    We have a total of 4786 unique words. This is our vocabulary size\n",
    "    \"\"\"\n",
    "    # 1) Convert raw dataset (dictionary of ordered labels per image) to list of labels\n",
    "    dset_im_words, _ = labels_dict2list(dataset_labels)\n",
    "    \n",
    "    # 2) Flatten the list \n",
    "    all_words = list(dset_im_words.values())\n",
    "    flat_list = []\n",
    "    for sublist in all_words:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    \n",
    "    # 3) Get set of unique words = vocabulary\n",
    "    unique_words = set(flat_list)\n",
    "    \n",
    "    # 4) Get dicitonary to map idx to words and viceversa\n",
    "    words2idx = dict()\n",
    "    idx2words = dict()\n",
    "    \n",
    "    set2list = list(unique_words)\n",
    "    for i in range(len(set2list)):\n",
    "        w = set2list[i]\n",
    "        words2idx[w] = i\n",
    "        idx2words[i] = w\n",
    "        \n",
    "    return dset_im_words, words2idx, idx2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_im_words, vocab2idx, idx2vocab = create_vocab(dataset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDict(d_img_words, d_img_embs, percent, val_number):\n",
    "\n",
    "    val_n = val_number\n",
    "    train_test_size = len(d_img_words) - val_n\n",
    "    train_n = int(train_test_size*percent)\n",
    "    test_n = train_test_size - train_n\n",
    "    \n",
    "    im_words = iter(d_img_words.items())      \n",
    "    im_embs = iter(d_img_embs.items())\n",
    "    \n",
    "    # Image - words\n",
    "    dtrain_imw = dict(itertools.islice(im_words, train_n))  \n",
    "    dtest_imw = dict(itertools.islice(im_words, test_n))   \n",
    "    dval_imw = dict(itertools.islice(im_words, val_n))\n",
    "    \n",
    "    \n",
    "    print('trainset size: ', len(dtrain_imw), 'dataset size: ',len(dtest_imw), 'val set size: ', len(dval_imw))\n",
    "    return dtrain_imw, dtest_imw, dval_imw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size:  16180 dataset size:  852 val set size:  500\n"
     ]
    }
   ],
   "source": [
    "dtrain_w, dtest_w, dval_w = splitDict(dset_im_words,image_embeddings, .95, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "class ADARIdataset(Dataset):\n",
    "    \"\"\"\n",
    "    Receives images and labels.\n",
    "    Returns tensor image and tensor labels\n",
    "    \"\"\"\n",
    "    def __init__(self, data_labels, word_embeddings, image_embeddings, vocab2idx, idx2vocab, img_path):\n",
    "\n",
    "        self.labels_data = data_labels # dictionary of images -> labels\n",
    "        self.word_embeds = word_embeddings\n",
    "        \n",
    "        self.images_names = list(self.labels_data.keys())    # names\n",
    "        self.images_embeds = list(image_embeddings.values()) # values\n",
    "        \n",
    "        self.vocab2idx = vocab2idx\n",
    "        self.idx2vocab = idx2vocab\n",
    "        \n",
    "        self.image_path = img_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_names)\n",
    "    \n",
    "    def name2idx(self):\n",
    "        self.name2idx = dict()\n",
    "        self.idx2name = dict()\n",
    "        for i, key in enumerate(self.images_names.keys()):\n",
    "            self.name2idx[key] = i\n",
    "            self.idx2name[i] = key\n",
    "        \n",
    "    def get_image_tensor(self, image_name):\n",
    "        \"\"\"\n",
    "        Gets image name and returns a tensor\n",
    "        \"\"\"\n",
    "        name = self.image_path + \"/\" + image_name\n",
    "        img = Image.open(name)\n",
    "        img = transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor()])(img)\n",
    "        \n",
    "        return img\n",
    "        \n",
    "    def get_labels_embeddings_from_idx(self, idx):\n",
    "\n",
    "        name_image = self.images_names[idx]\n",
    "        labels = self.labels_data[name_image]\n",
    "        labels = list(set(labels))\n",
    "        \n",
    "        # Set random distribution for setting a max number of labels\n",
    "        if len(labels) > 20:\n",
    "            labels = np.random.choice(labels, 20)\n",
    "        \n",
    "        # Get positive and negative labels\n",
    "        all_idx = list(self.vocab2idx.values())\n",
    "        pos_idxs = []\n",
    "        # Remove indexes that correspond to the positive labels\n",
    "        for l in labels:\n",
    "            v2i = self.vocab2idx[l]\n",
    "            pos_idxs.append(v2i)\n",
    "            if v2i in all_idx:\n",
    "                all_idx.remove(v2i)\n",
    "        \n",
    "        # Choose random labels as negative samples -> this can be improved with info about distance of labels\n",
    "        neg_idxs = np.random.choice(all_idx, len(labels))\n",
    "        \n",
    "        neg_samples = []\n",
    "        for n in neg_idxs:\n",
    "            neg_samples.append(self.idx2vocab[n])\n",
    "        \n",
    "        assert(len(labels) == len(neg_samples))\n",
    "        pos_w_embs = []\n",
    "        neg_w_embs = []\n",
    "        \n",
    "        # positive\n",
    "        for l in labels:\n",
    "            try:\n",
    "                pos_w_embs.append(self.word_embeds[l.lower()]) # appending 50 vector embedding\n",
    "            except:\n",
    "                try:\n",
    "                    pos_w_embs.append(glove_vocab[l.lower()])\n",
    "                except:\n",
    "                    pos_w_embs.append(AVG_VECTOR)\n",
    "        # negative\n",
    "        for nl in neg_samples:\n",
    "            try:\n",
    "                neg_w_embs.append(self.word_embeds[nl.lower()]) # appending 50 vector embedding\n",
    "            except:\n",
    "                try:\n",
    "                    neg_w_embs.append(glove_vocab[nl.lower()])\n",
    "                except:\n",
    "                    neg_w_embs.append(AVG_VECTOR)\n",
    "                    \n",
    "                    \n",
    "        return pos_w_embs, neg_w_embs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Return tensor image and label embedding\n",
    "        \"\"\"\n",
    "        name_image = self.images_names[index]\n",
    "        img = self.get_image_tensor(name_image)\n",
    "        \n",
    "        #image_emb = self.images_embeds[index] # list size 2048 \n",
    "        pos_label_embs, neg_label_embs = self.get_labels_embeddings_from_idx(index) # list size variable \n",
    "        \n",
    "        return img, pos_label_embs, neg_label_embs\n",
    " \n",
    "\n",
    "def collate(sequence):\n",
    "    \"\"\"\n",
    "    \"the input of this function is the output of function __getitem__\"\n",
    "    \"this gets BATCH_SIZE times GETITEM! \"\n",
    "    if batch_Size == 2 --> sequence is a list with length 2. \n",
    "    Each list is a tuple (image_embedding, labels_embedding) = (2048 vector, list of vectors size 50)\n",
    "    Pad labels with maximum from batch\n",
    "    \"\"\"\n",
    "    \n",
    "    # Concatenate all images in the batch\n",
    "    # For images (not embeddigns)\n",
    "    images = torch.cat(([torch.FloatTensor(batch[0]).view(-1, 3, 64, 64) for batch in sequence]), dim=0)\n",
    "    # For images embeddings\n",
    "    #images = torch.cat(([torch.FloatTensor(batch[0]).view(-1, 2048) for batch in sequence]), dim=0)\n",
    "    \n",
    "    # Pad labels with max_sequence_label\n",
    "    # batch 1 is batch * word embedding\n",
    "    pos_labels = pad_sequence([torch.FloatTensor(batch[1]) for batch in sequence], batch_first=True)\n",
    "    labels_length = torch.LongTensor([len(batch[1]) for batch in sequence])     \n",
    "\n",
    "    neg_labels = pad_sequence([torch.FloatTensor(batch[2]) for batch in sequence], batch_first=True)\n",
    "    \n",
    "    return images, pos_labels, neg_labels, labels_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ADARIdataset(dtrain_w, labels_embeddings, image_embeddings, vocab2idx, idx2vocab, im_path_fur)\n",
    "dataset_test = ADARIdataset(dtest_w, labels_embeddings, image_embeddings, vocab2idx, idx2vocab, im_path_fur)\n",
    "dataset_val = ADARIdataset(dval_w, labels_embeddings, image_embeddings, vocab2idx, idx2vocab, im_path_fur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 8 if cuda else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset_train, batch_size=batch_size, collate_fn = collate, shuffle=True, num_workers=num_workers, drop_last=False)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=batch_size, collate_fn = collate,shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=batch_size, collate_fn = collate,shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# to test dataloader\n",
    "it = iter(test_dataloader)\n",
    "\n",
    "min_ = 10000\n",
    "for i in range(len(test_dataloader)):\n",
    "    first = next(it)\n",
    "    if first[1].shape[1] < min_:\n",
    "        min_ = first[1].shape[1]\n",
    "print(min_)\n",
    "   # print(second[0].shape, second[1].shape, second[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The only combination I get to work is using the output of the LSTM, not the hiddens. \n",
    "    Can be either 1 direction or 2.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, n_layers, bidirectional, dropout):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bi = bidirectional\n",
    "        # lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                           hidden_dim,\n",
    "                           num_layers=n_layers,\n",
    "                           bidirectional=bidirectional,\n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "    def forward(self, labels, labels_lengths):\n",
    "\n",
    "        batch_size = labels.shape[0]\n",
    "        # --------------------------------   SHAPES -----------------------------------------------------\n",
    "        # labels ----------------------> [batch, max_len, 50] they come padded to go through the data loader\n",
    "\n",
    "        # embedded_label --------------> [batch size, max_length, emb dim] (64 dimensions for each of the 5 labels)\n",
    "        # packed_embdded --------------> [XXXX, emb dimension]\n",
    "        # out lstm shape --------------> [seq_len, batch_size, hidden_dim * directions (2 if bidirectional else 1)])\n",
    "        # Hidden lstm shape -----------> [batch_size, hidden_size*num_layers])\n",
    "        # Cell lstm shape -------------> [directions * layers, batch_size, hidden_size])\n",
    "        # REturn ----------------------> [seq_len * batch, vocab size]\n",
    "        # Using pad packed ------------> [seq_len, batch, vocab size]\n",
    "\n",
    "        # packed sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(labels, labels_lengths, \n",
    "                                                            enforce_sorted=False, batch_first=True)\n",
    "\n",
    "        # Lstm returns packed output \n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded) # hidden shape[num_layers*num_directions, batch, 50]\n",
    "\n",
    "        last_hidden = hidden[-1, :, :] # [batch, emb_dim=50]\n",
    "\n",
    "        \n",
    "        output, lens = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # output shape: [20, 64, 50]\n",
    "        \n",
    "        return last_hidden # last layer of hidden \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = False # so it fine tunes\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "    model_ft = torch.nn.Sequential(*(list(model_ft.children())[:-1]))\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    #num_ftrs = model_ft.fc.in_features\n",
    "#     model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "#     input_size = 64\n",
    "    \n",
    "    return model_ft\n",
    "\n",
    "model_ft = initialize_model(50, feature_extract)\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wim(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(Wim, self).__init__()   \n",
    "        \n",
    "        self.fc = nn.Linear(2048, embed_size)\n",
    "    \n",
    "    def forward(self, im):\n",
    "        return self.fc(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_devise(image_vector, Wim, label_true_vectors, label_random_vectors):\n",
    "    \n",
    "    image_v = normalize_vec(image_vector)         # [batch, 2048]\n",
    "    t_label = normalize_vec(label_true_vectors)   # [batch, 50]\n",
    "    t_j     = normalize_vec(label_random_vectors) # [batch, 50]\n",
    "    \n",
    "    W = Wim.fc.weight                              # [50, 2048]\n",
    "\n",
    "    #x = torch.mm(image_v, W.T) # [batch, 2048] x [2048, 50] -> [batch, 50] \n",
    "    x = Wim(image_v) # [batch, 50]\n",
    "    s_x_v = torch.mm(x, t_label.T) # [batch, 50] x [50, batch] -> [batch, batch]\n",
    "    s_x_vj = torch.mm(x, t_j.T) # [batch, 50] x [50, batch] -> [batch, batch]\n",
    "    \n",
    "    batch = image_v.shape[0]\n",
    "    # test with loop\n",
    "    loss = 0.0\n",
    "    for b in range(batch):\n",
    "        sxv_sum = s_x_v[b, :].sum()\n",
    "        sxvj_sum = s_x_vj[b, :].sum()\n",
    "        c = 0.2 - sxv_sum + sxvj_sum\n",
    "        loss_ind = torch.max(torch.zeros_like(c), c)\n",
    "        loss += loss_ind\n",
    "        \n",
    "    # end test with loop\n",
    "#     c = 0.2 - s_x_v + s_x_vj  \n",
    "#     print(c)\n",
    "#     loss = torch.max(torch.zeros_like(c), c)\n",
    "#     loss = loss.sum()\n",
    "\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cosine_similarity(image_vector, label_true_vectors, label_random_vectors):\n",
    "\n",
    "    v_image = image_vector         # [batch, 50]\n",
    "    t_label = label_true_vectors   # [batch, 50]\n",
    "    t_j     = label_random_vectors # [batch, 50]\n",
    "    \n",
    "    # Cosine similarity\n",
    "    d_true = F.cosine_similarity(v_image, t_label) #[batch]\n",
    "    d_contrast = F.cosine_similarity(v_image, t_j)\n",
    "    \n",
    "    c = 0.2 - d_true + d_contrast\n",
    "    loss = torch.max(torch.zeros_like(c), c)\n",
    "    loss = loss.sum()\n",
    "\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vec(vec):\n",
    "    norm = vec.norm(p=2, dim=1, keepdim=True)\n",
    "    vec_norm = vec.div(norm)\n",
    "    return vec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(img_cnn, wim, lstm, train_loader, optimizer):\n",
    "    img_cnn.train()\n",
    "    lstm.train()\n",
    "    wim.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, pos_labels, neg_labels, length) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device)\n",
    "        length = length.to(device)\n",
    "        \n",
    "        # Image representation \n",
    "        im_repres = img_cnn(data).squeeze(3).squeeze(2) # [batch, 2048]\n",
    "        \n",
    "        pos_labels = pos_labels.to(device) # [batch, max_len, 50]\n",
    "        neg_labels = neg_labels.to(device) # [batch, max_len, 50]\n",
    "        \n",
    "        # Lstm\n",
    "        pos_labels_vec = lstm(pos_labels, length) # [batch, 50]\n",
    "        neg_labels_vec = lstm(neg_labels, length) # [batch, 50]\n",
    "\n",
    "        \n",
    "        # Loss \n",
    "        loss = loss_devise(im_repres, wim, pos_labels_vec, neg_labels_vec)\n",
    "\n",
    "        if batch_idx % 20 == 0 and batch_idx != 0:\n",
    "            \n",
    "            print('loss: ', loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    loss_epoch = running_loss / len(train_loader)\n",
    "    print('------ Training -----')\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(img_cnn, wim, lstm, test_loader):\n",
    "    img_cnn.eval()\n",
    "    lstm.eval()\n",
    "    wim.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, pos_labels, neg_labels, length) in enumerate(test_loader):   \n",
    "            data = data.to(device)\n",
    "            length = length.to(device)\n",
    "            \n",
    "            # Image representation \n",
    "            im_repres = img_cnn(data).squeeze(3).squeeze(2) # [batch, 2048]\n",
    "\n",
    "            pos_labels = pos_labels.to(device) # [batch, max_len, 50]\n",
    "            neg_labels = neg_labels.to(device) # [batch, max_len, 50]\n",
    "\n",
    "            # Lstm\n",
    "            pos_labels_vec = lstm(pos_labels, length) # [batch, 50]\n",
    "            neg_labels_vec = lstm(neg_labels, length) # [batch, 50]\n",
    "\n",
    "            # Loss \n",
    "            loss = loss_devise(im_repres, wim, pos_labels_vec, neg_labels_vec)\n",
    "\n",
    "            if batch_idx % 20 == 0 and batch_idx != 0:\n",
    "                print('loss: ', loss.item())\n",
    "\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    loss_epoch = running_loss / len(test_loader)\n",
    "    print('------ Testing -----')\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t 0.weight\n",
      "\t 1.weight\n",
      "\t 1.bias\n",
      "\t 4.0.conv1.weight\n",
      "\t 4.0.bn1.weight\n",
      "\t 4.0.bn1.bias\n",
      "\t 4.0.conv2.weight\n",
      "\t 4.0.bn2.weight\n",
      "\t 4.0.bn2.bias\n",
      "\t 4.0.conv3.weight\n",
      "\t 4.0.bn3.weight\n",
      "\t 4.0.bn3.bias\n",
      "\t 4.0.downsample.0.weight\n",
      "\t 4.0.downsample.1.weight\n",
      "\t 4.0.downsample.1.bias\n",
      "\t 4.1.conv1.weight\n",
      "\t 4.1.bn1.weight\n",
      "\t 4.1.bn1.bias\n",
      "\t 4.1.conv2.weight\n",
      "\t 4.1.bn2.weight\n",
      "\t 4.1.bn2.bias\n",
      "\t 4.1.conv3.weight\n",
      "\t 4.1.bn3.weight\n",
      "\t 4.1.bn3.bias\n",
      "\t 4.2.conv1.weight\n",
      "\t 4.2.bn1.weight\n",
      "\t 4.2.bn1.bias\n",
      "\t 4.2.conv2.weight\n",
      "\t 4.2.bn2.weight\n",
      "\t 4.2.bn2.bias\n",
      "\t 4.2.conv3.weight\n",
      "\t 4.2.bn3.weight\n",
      "\t 4.2.bn3.bias\n",
      "\t 5.0.conv1.weight\n",
      "\t 5.0.bn1.weight\n",
      "\t 5.0.bn1.bias\n",
      "\t 5.0.conv2.weight\n",
      "\t 5.0.bn2.weight\n",
      "\t 5.0.bn2.bias\n",
      "\t 5.0.conv3.weight\n",
      "\t 5.0.bn3.weight\n",
      "\t 5.0.bn3.bias\n",
      "\t 5.0.downsample.0.weight\n",
      "\t 5.0.downsample.1.weight\n",
      "\t 5.0.downsample.1.bias\n",
      "\t 5.1.conv1.weight\n",
      "\t 5.1.bn1.weight\n",
      "\t 5.1.bn1.bias\n",
      "\t 5.1.conv2.weight\n",
      "\t 5.1.bn2.weight\n",
      "\t 5.1.bn2.bias\n",
      "\t 5.1.conv3.weight\n",
      "\t 5.1.bn3.weight\n",
      "\t 5.1.bn3.bias\n",
      "\t 5.2.conv1.weight\n",
      "\t 5.2.bn1.weight\n",
      "\t 5.2.bn1.bias\n",
      "\t 5.2.conv2.weight\n",
      "\t 5.2.bn2.weight\n",
      "\t 5.2.bn2.bias\n",
      "\t 5.2.conv3.weight\n",
      "\t 5.2.bn3.weight\n",
      "\t 5.2.bn3.bias\n",
      "\t 5.3.conv1.weight\n",
      "\t 5.3.bn1.weight\n",
      "\t 5.3.bn1.bias\n",
      "\t 5.3.conv2.weight\n",
      "\t 5.3.bn2.weight\n",
      "\t 5.3.bn2.bias\n",
      "\t 5.3.conv3.weight\n",
      "\t 5.3.bn3.weight\n",
      "\t 5.3.bn3.bias\n",
      "\t 5.4.conv1.weight\n",
      "\t 5.4.bn1.weight\n",
      "\t 5.4.bn1.bias\n",
      "\t 5.4.conv2.weight\n",
      "\t 5.4.bn2.weight\n",
      "\t 5.4.bn2.bias\n",
      "\t 5.4.conv3.weight\n",
      "\t 5.4.bn3.weight\n",
      "\t 5.4.bn3.bias\n",
      "\t 5.5.conv1.weight\n",
      "\t 5.5.bn1.weight\n",
      "\t 5.5.bn1.bias\n",
      "\t 5.5.conv2.weight\n",
      "\t 5.5.bn2.weight\n",
      "\t 5.5.bn2.bias\n",
      "\t 5.5.conv3.weight\n",
      "\t 5.5.bn3.weight\n",
      "\t 5.5.bn3.bias\n",
      "\t 5.6.conv1.weight\n",
      "\t 5.6.bn1.weight\n",
      "\t 5.6.bn1.bias\n",
      "\t 5.6.conv2.weight\n",
      "\t 5.6.bn2.weight\n",
      "\t 5.6.bn2.bias\n",
      "\t 5.6.conv3.weight\n",
      "\t 5.6.bn3.weight\n",
      "\t 5.6.bn3.bias\n",
      "\t 5.7.conv1.weight\n",
      "\t 5.7.bn1.weight\n",
      "\t 5.7.bn1.bias\n",
      "\t 5.7.conv2.weight\n",
      "\t 5.7.bn2.weight\n",
      "\t 5.7.bn2.bias\n",
      "\t 5.7.conv3.weight\n",
      "\t 5.7.bn3.weight\n",
      "\t 5.7.bn3.bias\n",
      "\t 6.0.conv1.weight\n",
      "\t 6.0.bn1.weight\n",
      "\t 6.0.bn1.bias\n",
      "\t 6.0.conv2.weight\n",
      "\t 6.0.bn2.weight\n",
      "\t 6.0.bn2.bias\n",
      "\t 6.0.conv3.weight\n",
      "\t 6.0.bn3.weight\n",
      "\t 6.0.bn3.bias\n",
      "\t 6.0.downsample.0.weight\n",
      "\t 6.0.downsample.1.weight\n",
      "\t 6.0.downsample.1.bias\n",
      "\t 6.1.conv1.weight\n",
      "\t 6.1.bn1.weight\n",
      "\t 6.1.bn1.bias\n",
      "\t 6.1.conv2.weight\n",
      "\t 6.1.bn2.weight\n",
      "\t 6.1.bn2.bias\n",
      "\t 6.1.conv3.weight\n",
      "\t 6.1.bn3.weight\n",
      "\t 6.1.bn3.bias\n",
      "\t 6.2.conv1.weight\n",
      "\t 6.2.bn1.weight\n",
      "\t 6.2.bn1.bias\n",
      "\t 6.2.conv2.weight\n",
      "\t 6.2.bn2.weight\n",
      "\t 6.2.bn2.bias\n",
      "\t 6.2.conv3.weight\n",
      "\t 6.2.bn3.weight\n",
      "\t 6.2.bn3.bias\n",
      "\t 6.3.conv1.weight\n",
      "\t 6.3.bn1.weight\n",
      "\t 6.3.bn1.bias\n",
      "\t 6.3.conv2.weight\n",
      "\t 6.3.bn2.weight\n",
      "\t 6.3.bn2.bias\n",
      "\t 6.3.conv3.weight\n",
      "\t 6.3.bn3.weight\n",
      "\t 6.3.bn3.bias\n",
      "\t 6.4.conv1.weight\n",
      "\t 6.4.bn1.weight\n",
      "\t 6.4.bn1.bias\n",
      "\t 6.4.conv2.weight\n",
      "\t 6.4.bn2.weight\n",
      "\t 6.4.bn2.bias\n",
      "\t 6.4.conv3.weight\n",
      "\t 6.4.bn3.weight\n",
      "\t 6.4.bn3.bias\n",
      "\t 6.5.conv1.weight\n",
      "\t 6.5.bn1.weight\n",
      "\t 6.5.bn1.bias\n",
      "\t 6.5.conv2.weight\n",
      "\t 6.5.bn2.weight\n",
      "\t 6.5.bn2.bias\n",
      "\t 6.5.conv3.weight\n",
      "\t 6.5.bn3.weight\n",
      "\t 6.5.bn3.bias\n",
      "\t 6.6.conv1.weight\n",
      "\t 6.6.bn1.weight\n",
      "\t 6.6.bn1.bias\n",
      "\t 6.6.conv2.weight\n",
      "\t 6.6.bn2.weight\n",
      "\t 6.6.bn2.bias\n",
      "\t 6.6.conv3.weight\n",
      "\t 6.6.bn3.weight\n",
      "\t 6.6.bn3.bias\n",
      "\t 6.7.conv1.weight\n",
      "\t 6.7.bn1.weight\n",
      "\t 6.7.bn1.bias\n",
      "\t 6.7.conv2.weight\n",
      "\t 6.7.bn2.weight\n",
      "\t 6.7.bn2.bias\n",
      "\t 6.7.conv3.weight\n",
      "\t 6.7.bn3.weight\n",
      "\t 6.7.bn3.bias\n",
      "\t 6.8.conv1.weight\n",
      "\t 6.8.bn1.weight\n",
      "\t 6.8.bn1.bias\n",
      "\t 6.8.conv2.weight\n",
      "\t 6.8.bn2.weight\n",
      "\t 6.8.bn2.bias\n",
      "\t 6.8.conv3.weight\n",
      "\t 6.8.bn3.weight\n",
      "\t 6.8.bn3.bias\n",
      "\t 6.9.conv1.weight\n",
      "\t 6.9.bn1.weight\n",
      "\t 6.9.bn1.bias\n",
      "\t 6.9.conv2.weight\n",
      "\t 6.9.bn2.weight\n",
      "\t 6.9.bn2.bias\n",
      "\t 6.9.conv3.weight\n",
      "\t 6.9.bn3.weight\n",
      "\t 6.9.bn3.bias\n",
      "\t 6.10.conv1.weight\n",
      "\t 6.10.bn1.weight\n",
      "\t 6.10.bn1.bias\n",
      "\t 6.10.conv2.weight\n",
      "\t 6.10.bn2.weight\n",
      "\t 6.10.bn2.bias\n",
      "\t 6.10.conv3.weight\n",
      "\t 6.10.bn3.weight\n",
      "\t 6.10.bn3.bias\n",
      "\t 6.11.conv1.weight\n",
      "\t 6.11.bn1.weight\n",
      "\t 6.11.bn1.bias\n",
      "\t 6.11.conv2.weight\n",
      "\t 6.11.bn2.weight\n",
      "\t 6.11.bn2.bias\n",
      "\t 6.11.conv3.weight\n",
      "\t 6.11.bn3.weight\n",
      "\t 6.11.bn3.bias\n",
      "\t 6.12.conv1.weight\n",
      "\t 6.12.bn1.weight\n",
      "\t 6.12.bn1.bias\n",
      "\t 6.12.conv2.weight\n",
      "\t 6.12.bn2.weight\n",
      "\t 6.12.bn2.bias\n",
      "\t 6.12.conv3.weight\n",
      "\t 6.12.bn3.weight\n",
      "\t 6.12.bn3.bias\n",
      "\t 6.13.conv1.weight\n",
      "\t 6.13.bn1.weight\n",
      "\t 6.13.bn1.bias\n",
      "\t 6.13.conv2.weight\n",
      "\t 6.13.bn2.weight\n",
      "\t 6.13.bn2.bias\n",
      "\t 6.13.conv3.weight\n",
      "\t 6.13.bn3.weight\n",
      "\t 6.13.bn3.bias\n",
      "\t 6.14.conv1.weight\n",
      "\t 6.14.bn1.weight\n",
      "\t 6.14.bn1.bias\n",
      "\t 6.14.conv2.weight\n",
      "\t 6.14.bn2.weight\n",
      "\t 6.14.bn2.bias\n",
      "\t 6.14.conv3.weight\n",
      "\t 6.14.bn3.weight\n",
      "\t 6.14.bn3.bias\n",
      "\t 6.15.conv1.weight\n",
      "\t 6.15.bn1.weight\n",
      "\t 6.15.bn1.bias\n",
      "\t 6.15.conv2.weight\n",
      "\t 6.15.bn2.weight\n",
      "\t 6.15.bn2.bias\n",
      "\t 6.15.conv3.weight\n",
      "\t 6.15.bn3.weight\n",
      "\t 6.15.bn3.bias\n",
      "\t 6.16.conv1.weight\n",
      "\t 6.16.bn1.weight\n",
      "\t 6.16.bn1.bias\n",
      "\t 6.16.conv2.weight\n",
      "\t 6.16.bn2.weight\n",
      "\t 6.16.bn2.bias\n",
      "\t 6.16.conv3.weight\n",
      "\t 6.16.bn3.weight\n",
      "\t 6.16.bn3.bias\n",
      "\t 6.17.conv1.weight\n",
      "\t 6.17.bn1.weight\n",
      "\t 6.17.bn1.bias\n",
      "\t 6.17.conv2.weight\n",
      "\t 6.17.bn2.weight\n",
      "\t 6.17.bn2.bias\n",
      "\t 6.17.conv3.weight\n",
      "\t 6.17.bn3.weight\n",
      "\t 6.17.bn3.bias\n",
      "\t 6.18.conv1.weight\n",
      "\t 6.18.bn1.weight\n",
      "\t 6.18.bn1.bias\n",
      "\t 6.18.conv2.weight\n",
      "\t 6.18.bn2.weight\n",
      "\t 6.18.bn2.bias\n",
      "\t 6.18.conv3.weight\n",
      "\t 6.18.bn3.weight\n",
      "\t 6.18.bn3.bias\n",
      "\t 6.19.conv1.weight\n",
      "\t 6.19.bn1.weight\n",
      "\t 6.19.bn1.bias\n",
      "\t 6.19.conv2.weight\n",
      "\t 6.19.bn2.weight\n",
      "\t 6.19.bn2.bias\n",
      "\t 6.19.conv3.weight\n",
      "\t 6.19.bn3.weight\n",
      "\t 6.19.bn3.bias\n",
      "\t 6.20.conv1.weight\n",
      "\t 6.20.bn1.weight\n",
      "\t 6.20.bn1.bias\n",
      "\t 6.20.conv2.weight\n",
      "\t 6.20.bn2.weight\n",
      "\t 6.20.bn2.bias\n",
      "\t 6.20.conv3.weight\n",
      "\t 6.20.bn3.weight\n",
      "\t 6.20.bn3.bias\n",
      "\t 6.21.conv1.weight\n",
      "\t 6.21.bn1.weight\n",
      "\t 6.21.bn1.bias\n",
      "\t 6.21.conv2.weight\n",
      "\t 6.21.bn2.weight\n",
      "\t 6.21.bn2.bias\n",
      "\t 6.21.conv3.weight\n",
      "\t 6.21.bn3.weight\n",
      "\t 6.21.bn3.bias\n",
      "\t 6.22.conv1.weight\n",
      "\t 6.22.bn1.weight\n",
      "\t 6.22.bn1.bias\n",
      "\t 6.22.conv2.weight\n",
      "\t 6.22.bn2.weight\n",
      "\t 6.22.bn2.bias\n",
      "\t 6.22.conv3.weight\n",
      "\t 6.22.bn3.weight\n",
      "\t 6.22.bn3.bias\n",
      "\t 6.23.conv1.weight\n",
      "\t 6.23.bn1.weight\n",
      "\t 6.23.bn1.bias\n",
      "\t 6.23.conv2.weight\n",
      "\t 6.23.bn2.weight\n",
      "\t 6.23.bn2.bias\n",
      "\t 6.23.conv3.weight\n",
      "\t 6.23.bn3.weight\n",
      "\t 6.23.bn3.bias\n",
      "\t 6.24.conv1.weight\n",
      "\t 6.24.bn1.weight\n",
      "\t 6.24.bn1.bias\n",
      "\t 6.24.conv2.weight\n",
      "\t 6.24.bn2.weight\n",
      "\t 6.24.bn2.bias\n",
      "\t 6.24.conv3.weight\n",
      "\t 6.24.bn3.weight\n",
      "\t 6.24.bn3.bias\n",
      "\t 6.25.conv1.weight\n",
      "\t 6.25.bn1.weight\n",
      "\t 6.25.bn1.bias\n",
      "\t 6.25.conv2.weight\n",
      "\t 6.25.bn2.weight\n",
      "\t 6.25.bn2.bias\n",
      "\t 6.25.conv3.weight\n",
      "\t 6.25.bn3.weight\n",
      "\t 6.25.bn3.bias\n",
      "\t 6.26.conv1.weight\n",
      "\t 6.26.bn1.weight\n",
      "\t 6.26.bn1.bias\n",
      "\t 6.26.conv2.weight\n",
      "\t 6.26.bn2.weight\n",
      "\t 6.26.bn2.bias\n",
      "\t 6.26.conv3.weight\n",
      "\t 6.26.bn3.weight\n",
      "\t 6.26.bn3.bias\n",
      "\t 6.27.conv1.weight\n",
      "\t 6.27.bn1.weight\n",
      "\t 6.27.bn1.bias\n",
      "\t 6.27.conv2.weight\n",
      "\t 6.27.bn2.weight\n",
      "\t 6.27.bn2.bias\n",
      "\t 6.27.conv3.weight\n",
      "\t 6.27.bn3.weight\n",
      "\t 6.27.bn3.bias\n",
      "\t 6.28.conv1.weight\n",
      "\t 6.28.bn1.weight\n",
      "\t 6.28.bn1.bias\n",
      "\t 6.28.conv2.weight\n",
      "\t 6.28.bn2.weight\n",
      "\t 6.28.bn2.bias\n",
      "\t 6.28.conv3.weight\n",
      "\t 6.28.bn3.weight\n",
      "\t 6.28.bn3.bias\n",
      "\t 6.29.conv1.weight\n",
      "\t 6.29.bn1.weight\n",
      "\t 6.29.bn1.bias\n",
      "\t 6.29.conv2.weight\n",
      "\t 6.29.bn2.weight\n",
      "\t 6.29.bn2.bias\n",
      "\t 6.29.conv3.weight\n",
      "\t 6.29.bn3.weight\n",
      "\t 6.29.bn3.bias\n",
      "\t 6.30.conv1.weight\n",
      "\t 6.30.bn1.weight\n",
      "\t 6.30.bn1.bias\n",
      "\t 6.30.conv2.weight\n",
      "\t 6.30.bn2.weight\n",
      "\t 6.30.bn2.bias\n",
      "\t 6.30.conv3.weight\n",
      "\t 6.30.bn3.weight\n",
      "\t 6.30.bn3.bias\n",
      "\t 6.31.conv1.weight\n",
      "\t 6.31.bn1.weight\n",
      "\t 6.31.bn1.bias\n",
      "\t 6.31.conv2.weight\n",
      "\t 6.31.bn2.weight\n",
      "\t 6.31.bn2.bias\n",
      "\t 6.31.conv3.weight\n",
      "\t 6.31.bn3.weight\n",
      "\t 6.31.bn3.bias\n",
      "\t 6.32.conv1.weight\n",
      "\t 6.32.bn1.weight\n",
      "\t 6.32.bn1.bias\n",
      "\t 6.32.conv2.weight\n",
      "\t 6.32.bn2.weight\n",
      "\t 6.32.bn2.bias\n",
      "\t 6.32.conv3.weight\n",
      "\t 6.32.bn3.weight\n",
      "\t 6.32.bn3.bias\n",
      "\t 6.33.conv1.weight\n",
      "\t 6.33.bn1.weight\n",
      "\t 6.33.bn1.bias\n",
      "\t 6.33.conv2.weight\n",
      "\t 6.33.bn2.weight\n",
      "\t 6.33.bn2.bias\n",
      "\t 6.33.conv3.weight\n",
      "\t 6.33.bn3.weight\n",
      "\t 6.33.bn3.bias\n",
      "\t 6.34.conv1.weight\n",
      "\t 6.34.bn1.weight\n",
      "\t 6.34.bn1.bias\n",
      "\t 6.34.conv2.weight\n",
      "\t 6.34.bn2.weight\n",
      "\t 6.34.bn2.bias\n",
      "\t 6.34.conv3.weight\n",
      "\t 6.34.bn3.weight\n",
      "\t 6.34.bn3.bias\n",
      "\t 6.35.conv1.weight\n",
      "\t 6.35.bn1.weight\n",
      "\t 6.35.bn1.bias\n",
      "\t 6.35.conv2.weight\n",
      "\t 6.35.bn2.weight\n",
      "\t 6.35.bn2.bias\n",
      "\t 6.35.conv3.weight\n",
      "\t 6.35.bn3.weight\n",
      "\t 6.35.bn3.bias\n",
      "\t 7.0.conv1.weight\n",
      "\t 7.0.bn1.weight\n",
      "\t 7.0.bn1.bias\n",
      "\t 7.0.conv2.weight\n",
      "\t 7.0.bn2.weight\n",
      "\t 7.0.bn2.bias\n",
      "\t 7.0.conv3.weight\n",
      "\t 7.0.bn3.weight\n",
      "\t 7.0.bn3.bias\n",
      "\t 7.0.downsample.0.weight\n",
      "\t 7.0.downsample.1.weight\n",
      "\t 7.0.downsample.1.bias\n",
      "\t 7.1.conv1.weight\n",
      "\t 7.1.bn1.weight\n",
      "\t 7.1.bn1.bias\n",
      "\t 7.1.conv2.weight\n",
      "\t 7.1.bn2.weight\n",
      "\t 7.1.bn2.bias\n",
      "\t 7.1.conv3.weight\n",
      "\t 7.1.bn3.weight\n",
      "\t 7.1.bn3.bias\n",
      "\t 7.2.conv1.weight\n",
      "\t 7.2.bn1.weight\n",
      "\t 7.2.bn1.bias\n",
      "\t 7.2.conv2.weight\n",
      "\t 7.2.bn2.weight\n",
      "\t 7.2.bn2.bias\n",
      "\t 7.2.conv3.weight\n",
      "\t 7.2.bn3.weight\n",
      "\t 7.2.bn3.bias\n"
     ]
    }
   ],
   "source": [
    "# MODELS \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "image_CNN = model_ft.to(device)\n",
    "W_image = Wim(50)\n",
    "W_image = W_image.to(device)\n",
    "\n",
    "words_lstm = LSTM(embedding_dim = 50, hidden_dim = 50, n_layers = 2,\n",
    "                 bidirectional = True, dropout=0.1).to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "\n",
    "params_to_update = image_CNN.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "\n",
    "params = list(params_to_update) + list(W_image.parameters()) + list(words_lstm.parameters())\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(params, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtrain_w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-4799e990c02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdtrain_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtest_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdval_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_im_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mimage_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdataset_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mlabels_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtrain_w' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "del dtrain_w, dtest_w, dval_w, dset_im_words, vocab2idx, idx2vocab\n",
    "del image_embeddings\n",
    "del dataset_labels \n",
    "del labels_embeddings \n",
    "del glove_vocab\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training epoch 0/9 --------\n",
      "loss:  0.0\n",
      "loss:  0.0\n",
      "loss:  0.0\n",
      "loss:  0.0\n",
      "loss:  0.0\n",
      "loss:  0.0\n",
      "loss:  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-2702c2617ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----Training epoch {}/{} --------'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train epoch: {}, loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-208-7dc8927afe0e>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(img_cnn, wim, lstm, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Image representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mim_repres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, 2048]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpos_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, max_len, 50]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1664\u001b[0;31m             \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "save_model_path = './saved_models/unifying/'\n",
    "for i in range(20):\n",
    "    print('-----Training epoch {}/{} --------'.format(i,9))\n",
    "    tr_loss = train_epoch(image_CNN, W_image, words_lstm, train_dataloader, optimizer)\n",
    "    print('train epoch: {}, loss: {}'.format(i, tr_loss))\n",
    "    print()\n",
    "    print('------Testing epoch {}/{} --------'.format(i,9))\n",
    "    tst_loss = test_epoch(image_CNN, test_dataloader)\n",
    "    print('test epoch: {}, loss: {}'.format(i, tst_loss))\n",
    "    \n",
    "    train_losses.append(tr_loss)\n",
    "    test_losses.append(tst_loss)\n",
    "    \n",
    "    save_path_im = save_model_path + 'cnnim_{}.pt'.format(i)\n",
    "    torch.save(image_CNN, save_path_im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
